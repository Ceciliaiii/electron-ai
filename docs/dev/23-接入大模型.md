# Main 进程接入大模型

## 准备工作
安装 npm 官网的 openai 包。
```powershell
npm install openai@5.21.0
```
并且注册 deepseek、百度千帆、硅基流动、智谱ai 等平台并获取 apikey。
### 定义ai对话相关全局类型
```ts
// ai对话相关
type DialogueMessageRole = 'user' | 'assistant'
interface DialogueMessageProps {
  role: DialogueMessageRole;
  content: string;
}

interface CreateDialogueProps {
  messages: DialogueMessageProps[];
  providerName: string;
  selectedModel: string;
  messageId: number;
  conversationId: number;
}

// ai对话返回数据块
interface UniversalChunk {
  isEnd: boolean;
  result: string;
}

interface DialogueBackStream {
  messageId: number;
  data: UniversalChunk & { isError?: boolean };
}
```

### 定义大模型请求和返回日志
```ts
// LogService.ts

// 大模型请求日志
  public logApiRequest(endpoint: string, data: any = {}, method: string = 'POST'): void {
    this.info(`API Request: ${endpoint}, Method: ${method}, Request: ${JSON.stringify(data)}`);
  }

  // 大模型响应日志
  public logApiResponse(endpoint: string, response: any = {}, statusCode: number = 200, responseTime: number = 0): void {
    if (statusCode >= 400) {
      this.error(`API Error Response: ${endpoint}, Status: ${statusCode}, Response Time: ${responseTime}ms, Response: ${JSON.stringify(response)}`);
    } else {
      this.debug(`API Response: ${endpoint}, Status: ${statusCode}, Response Time: ${responseTime}ms, Response: ${JSON.stringify(response)}`);
    }
  }

```

## provider 类逻辑
### 基类
```ts
// main/providers/BaseProvider.ts


// 基类  abstract抽象类 只能被继承
export abstract class BaseProvider {

    // 抽象方法chat 所有子类必须实现 参数定义role和大模型name
    // 返回promise（模型调用是网络请求，需要异步），适配流式响应（逐字逐句生成回复）
  abstract chat(messages: DialogueMessageProps[], modelName: string): 
  Promise<AsyncIterable<UniversalChunk>>
}
```

### 实现类
通过 openai 的 create 接口请求数据块，返回并适配流式响应，并翻译数据块，转化成统一的格式块。
```ts
// main/providers/OpenAIProvider.ts

import { BaseProvider } from "./BaseProvider";

import OpenAI from "openai";
import logManager from "../service/LogService";


// 翻译返回的数据块，转化成统一的格式块
function _transformChunk(chunk: OpenAI.Chat.Completions.ChatCompletionChunk): UniversalChunk {
  const choice = chunk.choices[0];
  return {
    isEnd: choice?.finish_reason === 'stop',
    result: choice?.delta?.content ?? '',
  }
}

// 用法参照npm/openai/usage
export class OpenAIProvider extends BaseProvider {

  private client: OpenAI;

//   index传openAISetting参数
  constructor(apiKey: string, baseURL: string) {
    super();
    // 实例化
    this.client = new OpenAI({ apiKey, baseURL });
  }

  async chat(messages: DialogueMessageProps[], model: string): Promise<AsyncIterable<UniversalChunk>> {
    const startTime = Date.now();

    const lastMessage = messages[messages.length - 1];

    logManager.logApiRequest('chat.completions.create', {
      model,
      lastMessage: lastMessage?.content?.substring(0, 100) + (lastMessage?.content?.length > 100 ? '...' : ''),
      messageCount: messages.length,
    }, 'POST');

    // 响应成功or失败
    try {
        // 调用openai的create接口，请求数据块
      const chunks = await this.client.chat.completions.create({
        model,
        messages, // 传所有的对话信息，ai才有上下文理解能力
        stream: true,
      });

      const responseTime = Date.now() - startTime;
      logManager.logApiResponse('chat.completions.create', { success: true }, 200, responseTime);
      // return chunk;
      return {
        async *[Symbol.asyncIterator]() {
          for await (const chunk of chunks) {
            // 翻译数据块
            yield _transformChunk(chunk);
          }
        }
      }
    } catch (error) {
      const responseTime = Date.now() - startTime;
      logManager.logApiResponse('chat.completions.create', { error: error instanceof Error ? error.message : String(error) }, 500, responseTime);
      throw error;
    }
  }
}

```

## 调用的入口
定义大模型配置，通过 `createProvider` 获取大模型实例，并调用 `chat` 方法进行对话。
```ts
// main/providers/index.ts

import { OpenAIProvider } from "./OpenAIProvider";


// 大模型配置
const providers = [
  {
    id: 1,
    name: 'bigmodel',
    title: '智谱AI',
    models: ['glm-4.5-flash'],
    openAISetting: {
      baseURL: 'https://open.bigmodel.cn/api/paas/v4',
      apiKey: '6608b9c18f2d4de9a15948021a3281f5.Sjl0ulDPbW7ywzEc',
    },
    createdAt: new Date().getTime(),
    updatedAt: new Date().getTime()
  },
  {
    id: 2,
    name: 'deepseek',
    title: '深度求索 (DeepSeek)',
    models: ['deepseek-chat'],
    openAISetting: {
      baseURL: 'https://api.deepseek.com/v1',
      apiKey: 'sk-91f83453547040439222c248ef28e324',
    },
    createdAt: new Date().getTime(),
    updatedAt: new Date().getTime()
  },
  {
    id: 3,
    name: 'siliconflow',
    title: '硅基流动',
    models: ['Qwen/Qwen3-8B', 'deepseek-ai/DeepSeek-R1-0528-Qwen3-8B'],
    openAISetting: {
      baseURL: 'https://api.siliconflow.cn/v1',
      apiKey: 'sk-hlkdyqzuhqljshjyqlxdngcxcbfofpeejiyjsjytaixfqtjj',
    },
    createdAt: new Date().getTime(),
    updatedAt: new Date().getTime()
  },
  {
    id: 4,
    name: 'qianfan',
    title: '百度千帆',
    models: ['ernie-speed-128k', 'ernie-4.0-8k', 'ernie-3.5-8k'],
    openAISetting: {
      baseURL: 'https://qianfan.baidubce.com/v2',
      apiKey: 'sk-igenlbjuivlwbwuntfhigvianptdfzxkuyjuifvpmphcaivg',
    },
    createdAt: new Date().getTime(),
    updatedAt: new Date().getTime()
  },
];


// 大模型调用入口
export function createProvider(name: string) {
  // TODO: const provider = config

  if (!providers) {
    throw new Error('provider config not found');
  }

  for (const provider of providers) {
    if (provider.name === name) {
      if (!provider.openAISetting?.apiKey || !provider.openAISetting?.baseURL) {
        throw new Error('apiKey or baseURL not found');
      }
      // TODO: setting里的大模型展示设置

      return new OpenAIProvider(provider.openAISetting.apiKey, provider.openAISetting.baseURL);
    }
  }
}
```

## main 与 render 的交互
在 main 窗口中，main 进程监听 `start_a_dialogue` 事件，接受 render 的 ai 对话请求，并调用 `provider.chat` 进行对话，返回数据块，并通过 `send()` 发送给 render 进程。
```ts
// main/wins/main.ts

// 监听start-a-dialogue事件，接收render进程发起的ai对话请求
  ipcMain.on(IPC_EVENTS.START_A_DIALOGUE, async (_event, props: CreateDialogueProps) => {
    const { providerName, messages, messageId, selectedModel } = props;
    const mainWindow = windowManager.get(WINDOW_NAMES.MAIN);

    if (!mainWindow) {
      throw new Error('mainWindow not found');
    }

    try {

      // 调用 chat，返回一个可迭代对象 chunks，用于分块返回结果
      const provider = createProvider(providerName);
      const chunks = await provider?.chat(messages, selectedModel);

      if(!chunks){
        throw new Error('chunks or stream not found');
      }

      for await (const chunk of chunks) {
        // 分块
        const chunkContent = {
          messageId,
          data: chunk
        }

        // 向main窗口render进程返回分块结果
        mainWindow.webContents.send(IPC_EVENTS.START_A_DIALOGUE + 'back' + messageId, chunkContent);
      }

    } catch (error) {
      const errorContent = {
        messageId,
        data: {
          isEnd: true,
          isError: true,
          result: error instanceof Error ? error.message : String(error),
        }
      }

      // 同理，返回errorContent
      mainWindow.webContents.send(IPC_EVENTS.START_A_DIALOGUE + 'back' + messageId, errorContent);
    }
  })
```