# render 进程接入大模型（第一次对话）
[ !!! ] 里程碑

## 准备工作
```powershell
npm install dotenv-cli@11.0.0
```
在 `package.json` 中修改启动命令，使其在环境变量的apikey添加到大模型配置 providers 中：
```json
 "scripts": {
    "start": "dotenv -e .env -- electron-forge start",
    ...
  },
```

## 封装 apikey
将 apikey 放入 `.env` 文件中：
```
# 智谱ai
BIGMODEL_API_KEY='...'

# deepseek
DEEPSEEK_API_KEY='...'

# 硅基流动
SILICONFLOW_API_KEY='...'

# 百度千帆
QIANFAN_API_KEY='...'
```
在大模型调用中，通过 `process.env.BIGMODEL_API_KEY` 获取 apikey。
```ts
// main/providers/index.ts

// 大模型配置
const providers = [
  {
    id: 1,
    name: 'bigmodel',
    title: '智谱AI',
    models: ['glm-4.5-flash'],
    openAISetting: {
      baseURL: 'https://open.bigmodel.cn/api/paas/v4',
      apiKey: process.env.BIGMODEL_API_KEY || '',
    },
    createdAt: new Date().getTime(),
    updatedAt: new Date().getTime()
  },
//   ...
];

```

## 封装 开始对话 和 回调
```ts
// global.d.ts

interface WindowApi {

  startADialogue: (params: CreateDialogueProps) => void;
  onDialogueBack: (cb: (data: DialogueBackStream) => void, messageId: number) => () => void;

}
```
render 进程发送 `startDialogue` 消息给 main，main 进程处理结束后将流式数据返回给 render：
```ts
// preload.ts

const api: WindowApi = {

  // render进程发送一个消息：创建一个对话
  // 触发main进程 main/wins/main窗口 的ipcMain.on
  startADialogue: (params: CreateDialogueProps) => ipcRenderer.send(IPC_EVENTS.START_A_DIALOGUE, params),



  // render监听main的ai流式响应，cb处理main进程的流式数据，messageId匹配响应的对话
  onDialogueBack: (cb: (data: DialogueBackStream) => void, messageId: number) => {
    // 接受main进程推送的data流式数据，并转发给render进程的cb回调，前端能实时处理数据
    const callback = (_event: Electron.IpcRendererEvent, data: DialogueBackStream) => cb(data);

    // 监听main进程推送的事件（start-a-dialogue + back + messageId），只接受当前messageId的流式数据
    ipcRenderer.on(IPC_EVENTS.START_A_DIALOGUE + 'back' + messageId, callback);

    // 返回一个停止监听，调用时防止内存泄漏
    return () => ipcRenderer.removeListener(IPC_EVENTS.START_A_DIALOGUE + 'back' + messageId, callback)
  },

}

```

## 消息发送 & 流式响应处理
发送用户消息 → 初始化 AI 加载状态 → 监听流式回复 → 实时更新消息内容

### 监听流式响应 & 终止监听
做到了 “手动停止” 与 “自动停止” 双场景：
 - 每收到主进程推送的流式数据，先调用外部传入的 `cb`，将数据转发给外部处理，如拼接文本、更新 UI。
 - 若 `isEnd = true`，ai响应结束，调用 `stop()` 停止监听，并释放引用。
 - 将 `stop()` 作为返回值给外部，做到 “手动停止” 与 “自动停止”。
```ts
// renderer/utils/dialogue.ts

export function listenDialogueBack(cb: (data: DialogueBackStream) => void, messageId: number) {
    // 调用 onDialogueBack
    let stop: (() => void) | void = window.api.onDialogueBack
    ((stream: DialogueBackStream) => {
        cb(stream)
        if(!stream.data.isEnd) return
        stop?.()
        stop = void 0    // 释放引用，避免内存泄漏
    }, messageId);

    return stop
}
```


### 发送消息处理
```ts
// renderer/store/messages.ts

// 发送消息方法
  async function sendMessage(message: Omit<Message, 'id' | 'createdAt'>) {
    // 先保存用户发送的消息
    await addMessage(message);

    // 新增一条loadingMessage，返回其id

    const loadingMsgId = await addMessage({
      conversationId: message.conversationId,
      type: 'answer',
      content: '...',  // 让前端先显示加载中消息
      status: 'loading',
    });
    
    // 获取当前对话
    const conversation = conversationsStore.getConversationById(message.conversationId);
    if(!conversation) return loadingMsgId;

    // 获取当前provider
    const provider = providersStore.allProviders.find(item => item.id === conversation.providerId);
    if (!provider) return loadingMsgId;


    // 存储当前 AI 消息的流式内容拼接结果
    // 防止多对话串流
    msgContentMap.set(loadingMsgId, '')

    // 拿到ai返回值，调用cb
    let streamCallback: ((stream: DialogueBackStream) => Promise<void>) | void 
    = async (stream) => {
      const {data, messageId} = stream

      // 获取回复状态
      const getStatus = (data: DialogueBackStream['data']): MessageStatus => {
        if(data.isError) return 'error'

        if(data.isEnd) return 'success'

        return 'streaming'
      }

      // 拼接流式内容
      msgContentMap.set(messageId, msgContentMap.get(messageId) + data.result)

      const _update = {
        content: msgContentMap.get(messageId) || '',
        status: getStatus(data),
        updateAt: Date.now(),
      } as unknown as Message


      await nextTick()

      // 将拼接后的内容 + 最新状态同步到store内存
      updateMessage(messageId, _update)
      // ai响应结束，删除map记录，释放回调引用  
      if(data.isEnd) {
        msgContentMap.delete(messageId)
        streamCallback = void 0
      }
    }

    // 存放不同对话的stop方法，用于停止监听
    stopMethods.set(loadingMsgId, listenDialogueBack(streamCallback, loadingMsgId))

    // 过滤loadingMessage，将剩余msg映射为ai模型的格式
    const messages = messagesByConversationId.value(message.conversationId)
    .filter(item => item.status !== 'loading').map(item => ({
      role: item.type === 'question' ? 'user' : 'assistant' as DialogueMessageRole,
      content: item.content,
    }))

    // 向主进程发送对话请求，触发其调用ai模型
    await window.api.startADialogue({
      messageId: loadingMsgId,
      providerName: provider.name,
      selectedModel: conversation.selectedModel,
      conversationId: message.conversationId,
      messages,
    });


    // 返回loadingMessage的id，供外部后续操作（如：主动取消对话时，调用id.stop()）
    return loadingMsgId;
  }

```

## 实际应用
在创建对话后，调用 sendMessage 将消息发送给大模型：
```ts
// renderer/views/conversation.vue

// 创建对话后，直接跳转
function afterCreateConversation(id: number, firstMsg: string) {
  if (!id) return;
  router.push(`/conversation/${id}`);
  messagesStore.sendMessage({
    type: 'question',
    content: firstMsg,
    conversationId: id 
  })
  message.value = '';  // 清空输入框内容
}
```
发送后，ai返回的 message 即存在内存store中，将内存的 message 传给流式渲染组件 `message-list`：
```html
 <message-list :messages="messagesStore.messagesByConversationId(conversationId)" />
```